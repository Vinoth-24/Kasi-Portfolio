{"status":"ok","feed":{"url":"https://medium.com/feed/@vino24995","title":"Stories by Kasi Vinoth S on Medium","link":"https://medium.com/@vino24995?source=rss-1afae9e18583------2","author":"","description":"Stories by Kasi Vinoth S on Medium","image":"https://cdn-images-1.medium.com/fit/c/150/150/0*wB8iPFESKVfwGXjS"},"items":[{"title":"Introduction to Data Science and Understanding Linear Regression in a simpler way","pubDate":"2022-03-02 10:00:57","link":"https://medium.com/@vino24995/introduction-to-data-science-and-understanding-linear-regression-in-a-simpler-way-f19b798d90e1?source=rss-1afae9e18583------2","guid":"https://medium.com/p/f19b798d90e1","author":"Kasi Vinoth S","thumbnail":"https://cdn-images-1.medium.com/max/416/1*cvOboIRcEQDf2w8vo9L8qg.png","description":"\n<h3>Introduction to Data Science and Understanding Linear Regression</h3>\n<p>Here is a brief introduction of\u00a0me.</p>\n<p>My name is Kasi Vinoth, and I hold a Masters degree in Nanotechnology from India. The inspiration to pursue Nanotechnology further eluded me and I finally tried out a variety of things. Developing algorithms and coding has always been a personal interest of\u00a0mine.</p>\n<p>Its no surprise that I have soon become fascinated with Machine learning algorithms and data science in general. As a result of my curiosity, I am currently studying courses on Data Science and the topics around it. As I share what I have learned, I hope it will help me grow as a professional, and also help others who are starting\u00a0out.</p>\n<p>So let\u2019s get started, shall\u00a0we?</p>\n<h3><strong>INTRODUCTION</strong></h3>\n<p>In this article, I am going to show you a glimpse of what Data Science is. Although I have a broad spectrum to cover, I hope to keep my discussion precise and\u00a0simple.</p>\n<p>It is no secret that Data Science is one of the most popular career paths presently. The superficial demand for this job is not slowing down at any rate as ironically predicted by the Data scientists themselves.</p>\n<p>A Data Scientist studies data for the purpose of creating insights into a problem via extraction, analysis, storage, and visualization. With the guidance of a Data Scientist, companies can take data-driven decisions. It can take quite a while for Data Science process to go from cleaning data to implementing machine learning algorithms and also deployment.</p>\n<p>Let\u2019s keep it simple and take one step at a time. What do we mean by data extraction?</p>\n<h4><strong>DATA EXTRACTION</strong></h4>\n<p>A Data extraction process includes the acquiring, repurposing and refining of data from various forms (structurally and unstructured) so that the data can be utilized. Many companies use ETL (Extract, Transform, Load), a data integration process to organize data from multiple sources into one data warehouse. Using these extracted data as the basis for Exploratory data analysis (EDA), we can now begin to investigate these\u00a0data.</p>\n<h4><strong>EXPLORATORY DATA\u00a0ANALYSIS</strong></h4>\n<p>EDA is a means of preprocessing and analyzing data. With the visualization methods, we can gain further insight into the dataset\u2019s characteristics. We come to understand more about our data and choose models based on that understanding.</p>\n<h4><strong>Why ML ALGORITHMS?</strong></h4>\n<p>Machine learning involves a set of algorithms that are trained with huge volumes of data. ML Algorithms have the potential to learn and improve their efficiency by passing historic data through them. The trained models can now be used to predict results based on unseen data. The idea behind any predictive modelling is primarily concerned with making accurate predictions by minimizing the loss function(error) of the\u00a0model.</p>\n<h4><strong>CLASSIFICATION</strong></h4>\n<p>Machine Learning Algorithms can be classified into 3\u00a0types:</p>\n<p>1. Supervised Learning\u200a\u2014\u200aOutput variable (dependent variables) is predicted with the help of predictors (Independent variables). Examples include decision trees, random forests, and regression models.</p>\n<p>2. Unsupervised Learning\u200a\u2014\u200aThere is no output variable in this algorithm. Rather, we segment or cluster the data into different groups (clusters) based on specific characteristics. Examples include K-means, Hierarchical clustering, and Apriori algorithms.</p>\n<p>3. Reinforcement Learning\u200a\u2014\u200aUsing feedback mechanisms, this algorithm learns to make a sequence of decisions in a given environment.</p>\n<p>At first, we will start focusing on Supervised Learning\u200a\u2014\u200aAn algorithm that is used to train a model on input data to predict a particular output variable.</p>\n<p>There are two types of Supervised Learning techniques:</p>\n<ol>\n<li>Regression</li>\n<li>Classification</li>\n</ol>\n<p>We will only look into Regression techniques in this\u00a0article.</p>\n<h4><strong>REGRESSION</strong></h4>\n<p>A Regression model provides an algorithm that understands the relationship between one or more independent variables and a scalar dependent or target variable. For eg\u200a\u2014\u200aThe relationship between height and weight can be described using Regression techniques(Linear Regression).</p>\n<p>Regression can be used on any Machine Learning problems that involves prediction of continuous data. Some real life problems that uses regressive techniques are Stock prices estimation, Weather analysis, Time series forecasting etc.</p>\n<p>Some of the Regression Algorithms are listed\u00a0below:</p>\n<ul>\n<li>Linear Regression</li>\n<li>Logistic Regression</li>\n<li>Polynomial Regression</li>\n<li>Ridge Regression</li>\n<li>Lasso Regression</li>\n<li>Quantile Regression</li>\n</ul>\n<p>Every Algorithms has its own advantages and purpose to be used in particular Regressive problems. We will be starting with Linear Regression on this\u00a0article.</p>\n<h3><strong>LINEAR REGRESSION</strong></h3>\n<p>In this section, I will help you get familiar with the following.</p>\n<ol>\n<li>What is Linear Regression?</li>\n<li>Cost Function for Linear Regression</li>\n<li>Gradient Descent Algorithm</li>\n<li>R squared and Adjusted R\u00a0squared</li>\n</ol>\n<h4><strong>What is Linear Regression?</strong></h4>\n<p>The aim of Linear Regression model is to create a best fit line from the training data and optimizing the intercept and weights, thus the Cost function is minimal. In other words, it finds the linear relationship between the independent and dependent variables.</p>\n<p>There are two types of Linear Regression: <br>Simple Linear Regression\u200a\u2014\u200aIf there are only one predictor or independent variable present then we use Simple Linear Regression to predict the target variable. <br>Multi Linear Regression\u200a\u2014\u200aIf there are more than one predictor or independent variable present then we can use Multi Linear Regression to predict target variable.</p>\n<p>The equation of Simple Linear Regression is as follows:<br><strong><em>\u0177=\u03b2\u2080+\u03b2\u2081x</em></strong><br>Here \u03b2\u2080 is called the intercept where the line intercepts the y-axis, \u03b2\u2081 is the coefficient or weight of the data points and it is also the slope of the line.<br>Both \u03b2\u2080 and \u03b2\u2081are the weights that are updated in order to get the best fit\u00a0line.</p>\n<p>For Multi Linear Regression, the equation is a little different.<br><strong><em>\u0177=\u03b2\u2080+\u03b2\u2081x\u2081+\u03b2\u2082x\u2082+\u2026+\u03b2\u2099x\u2099</em></strong><strong><br></strong>For more than one input features, We use the above equation to represent a straight line. \u03b2\u2080, \u03b2\u2081, \u03b2\u2082 and \u03b2\u2099 are the coefficients or weights and n is number of input features.</p>\n<p>For Simple Linear Regression, the best fit line will be a two-dimensional line plot. But for Multi Linear Regression, the best fit line will be multi dimensional and can be described using a hyperplane.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/416/1*cvOboIRcEQDf2w8vo9L8qg.png\"><figcaption>Simple Linear Regression plot</figcaption></figure><h4><strong>Cost Function</strong></h4>\n<p>The cost function is the average of the errors(predicted-actual values)for n data points occurred during the training period. We have to minimize this cost function by updating the weights to get the best fit line. The equation for Cost function is as\u00a0follows:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/320/0*iBuU1dZChL6RsN6-.png\"></figure><p>This process is done by plotting weights vs the cost functions. By updating the weights, we can plot for different cost functions. This plotting can be done by taking a hypothesis that the intercept= 0. The resultant graph gives us a U shaped curve called the Gradient\u00a0Descent.</p>\n<h4>GRADIENT DESCENT</h4>\n<p>Gradient descent is used as an optimization algorithm to find the weights for the minimal Cost function. This will lead to finding the best fit line for our data points. The point at which the Cost function is minimal is called the Global\u00a0minima.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/699/1*FeWOP7MFolo9PDnvaaXLPg.png\"><figcaption>Gradient Descent for Linear Regression</figcaption></figure><p>The equation used in Gradient Descent is called the convergence algorithm which is give\u00a0below.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/361/1*lyi3WJA2XxP7a5LzDhbqcA.png\"></figure><p>By repeating the above equation, we will reach convergence i.e. Minimal cost function.</p>\n<p>We navigate to the Global minima by applying a derivative of slope with a small learning rate (i.e. alpha) to the previous weights. If the slope is positive, then we get a positive derivative and if the slope is negative, then we get a negative derivative.</p>\n<p>Here, Learning rate determines at which speed we must move towards the global minima. Having a huge value for learning rate will lead to jumping out of global minima, thus does not converge. Also having a very smaller value of learning rate will take forever for the algorithm to reach global minima. Common learning rates are\u200a\u2014\u200a0.01, 0.001,\u00a00.0001.</p>\n<p>Once the gradient descent algorithm converges, It means that we have reached Global minima or the minimal Cost Function. These weights used to reach the global minima will be our weights for the best fit line equation.</p>\n<p>The cost function used in Linear regression does not create Local minima. Therefore we can worry about that when we go through Neural network where we learn different types of optimizers to solve this\u00a0problem.</p>\n<h4>R\u00b2 and ADJUSTED\u00a0R\u00b2</h4>\n<p>R\u00b2 and Adjusted R\u00b2 are called the coefficient of determination and it tells us the strength of linear relationship that our model can explain.<br>R squared can be defined as how well a model is fit using Linear Regression. The formula for R squared is given\u00a0below.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/404/1*f4AUmkE5Wx112olQULYgBA.png\"></figure><p>Here, SS(Regression) is the sum of squares of residuals or errors, SS(Total) is the total sum of squares i.e. sum of distance between the observed data and its mean. SST tells us how the observed data is dispersed around the\u00a0mean.</p>\n<p>If the R\u00b2 is a bigger number then our model has fitted the data points properly and vice versa. <br>The problem with R squared occurs when we deal with Multi Linear Regression. Adding features to our dataset will increase the value of R\u00b2 even though the features have no correlation with the output variable.</p>\n<p>In order to prevent this overfitting, We use Adjusted R\u00b2 which generalizes the value of R\u00b2 to the optimal value. The formula for Adjusted R\u00b2 is given\u00a0below.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/494/1*z33eWfw-6pu-tBp8ienweg.png\"></figure><p>Here N is the total number of samples or data points and p is the total number of features or independent variables.</p>\n<p>As the number of irrelevant features keeps increasing, the values of Adjusted R\u00b2 keeps decreasing. For relevant features, the R\u00b2 value in the numerator will be increased tremendously, thus impacting the Adjusted R\u00b2 value\u00a0also.</p>\n<h3>End Notes</h3>\n<p>We had a brief into about Machine Learning. We also have covered most of the topics related to Linear Regression. If you are interested to learn the math regarding Gradient descent, then you can refer this blog\u200a\u2014\u200a<a href=\"https://www.analyticsvidhya.com/blog/2021/04/gradient-descent-in-linear-regression/\">https://www.analyticsvidhya.com/blog/2021/04/gradient-descent-in-linear-regression/</a></p>\n<p>Please feel free to connect with me on <a href=\"https://www.linkedin.com/in/vinoth24/\">LinkedIn </a>and share your valuable inputs. Kindly have a look at my <a href=\"https://kasi-vinoth-s-my-data-science-portfolio.webflow.io/\">Portfolio</a>.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=f19b798d90e1\" width=\"1\" height=\"1\" alt=\"\">\n","content":"\n<h3>Introduction to Data Science and Understanding Linear Regression</h3>\n<p>Here is a brief introduction of\u00a0me.</p>\n<p>My name is Kasi Vinoth, and I hold a Masters degree in Nanotechnology from India. The inspiration to pursue Nanotechnology further eluded me and I finally tried out a variety of things. Developing algorithms and coding has always been a personal interest of\u00a0mine.</p>\n<p>Its no surprise that I have soon become fascinated with Machine learning algorithms and data science in general. As a result of my curiosity, I am currently studying courses on Data Science and the topics around it. As I share what I have learned, I hope it will help me grow as a professional, and also help others who are starting\u00a0out.</p>\n<p>So let\u2019s get started, shall\u00a0we?</p>\n<h3><strong>INTRODUCTION</strong></h3>\n<p>In this article, I am going to show you a glimpse of what Data Science is. Although I have a broad spectrum to cover, I hope to keep my discussion precise and\u00a0simple.</p>\n<p>It is no secret that Data Science is one of the most popular career paths presently. The superficial demand for this job is not slowing down at any rate as ironically predicted by the Data scientists themselves.</p>\n<p>A Data Scientist studies data for the purpose of creating insights into a problem via extraction, analysis, storage, and visualization. With the guidance of a Data Scientist, companies can take data-driven decisions. It can take quite a while for Data Science process to go from cleaning data to implementing machine learning algorithms and also deployment.</p>\n<p>Let\u2019s keep it simple and take one step at a time. What do we mean by data extraction?</p>\n<h4><strong>DATA EXTRACTION</strong></h4>\n<p>A Data extraction process includes the acquiring, repurposing and refining of data from various forms (structurally and unstructured) so that the data can be utilized. Many companies use ETL (Extract, Transform, Load), a data integration process to organize data from multiple sources into one data warehouse. Using these extracted data as the basis for Exploratory data analysis (EDA), we can now begin to investigate these\u00a0data.</p>\n<h4><strong>EXPLORATORY DATA\u00a0ANALYSIS</strong></h4>\n<p>EDA is a means of preprocessing and analyzing data. With the visualization methods, we can gain further insight into the dataset\u2019s characteristics. We come to understand more about our data and choose models based on that understanding.</p>\n<h4><strong>Why ML ALGORITHMS?</strong></h4>\n<p>Machine learning involves a set of algorithms that are trained with huge volumes of data. ML Algorithms have the potential to learn and improve their efficiency by passing historic data through them. The trained models can now be used to predict results based on unseen data. The idea behind any predictive modelling is primarily concerned with making accurate predictions by minimizing the loss function(error) of the\u00a0model.</p>\n<h4><strong>CLASSIFICATION</strong></h4>\n<p>Machine Learning Algorithms can be classified into 3\u00a0types:</p>\n<p>1. Supervised Learning\u200a\u2014\u200aOutput variable (dependent variables) is predicted with the help of predictors (Independent variables). Examples include decision trees, random forests, and regression models.</p>\n<p>2. Unsupervised Learning\u200a\u2014\u200aThere is no output variable in this algorithm. Rather, we segment or cluster the data into different groups (clusters) based on specific characteristics. Examples include K-means, Hierarchical clustering, and Apriori algorithms.</p>\n<p>3. Reinforcement Learning\u200a\u2014\u200aUsing feedback mechanisms, this algorithm learns to make a sequence of decisions in a given environment.</p>\n<p>At first, we will start focusing on Supervised Learning\u200a\u2014\u200aAn algorithm that is used to train a model on input data to predict a particular output variable.</p>\n<p>There are two types of Supervised Learning techniques:</p>\n<ol>\n<li>Regression</li>\n<li>Classification</li>\n</ol>\n<p>We will only look into Regression techniques in this\u00a0article.</p>\n<h4><strong>REGRESSION</strong></h4>\n<p>A Regression model provides an algorithm that understands the relationship between one or more independent variables and a scalar dependent or target variable. For eg\u200a\u2014\u200aThe relationship between height and weight can be described using Regression techniques(Linear Regression).</p>\n<p>Regression can be used on any Machine Learning problems that involves prediction of continuous data. Some real life problems that uses regressive techniques are Stock prices estimation, Weather analysis, Time series forecasting etc.</p>\n<p>Some of the Regression Algorithms are listed\u00a0below:</p>\n<ul>\n<li>Linear Regression</li>\n<li>Logistic Regression</li>\n<li>Polynomial Regression</li>\n<li>Ridge Regression</li>\n<li>Lasso Regression</li>\n<li>Quantile Regression</li>\n</ul>\n<p>Every Algorithms has its own advantages and purpose to be used in particular Regressive problems. We will be starting with Linear Regression on this\u00a0article.</p>\n<h3><strong>LINEAR REGRESSION</strong></h3>\n<p>In this section, I will help you get familiar with the following.</p>\n<ol>\n<li>What is Linear Regression?</li>\n<li>Cost Function for Linear Regression</li>\n<li>Gradient Descent Algorithm</li>\n<li>R squared and Adjusted R\u00a0squared</li>\n</ol>\n<h4><strong>What is Linear Regression?</strong></h4>\n<p>The aim of Linear Regression model is to create a best fit line from the training data and optimizing the intercept and weights, thus the Cost function is minimal. In other words, it finds the linear relationship between the independent and dependent variables.</p>\n<p>There are two types of Linear Regression: <br>Simple Linear Regression\u200a\u2014\u200aIf there are only one predictor or independent variable present then we use Simple Linear Regression to predict the target variable. <br>Multi Linear Regression\u200a\u2014\u200aIf there are more than one predictor or independent variable present then we can use Multi Linear Regression to predict target variable.</p>\n<p>The equation of Simple Linear Regression is as follows:<br><strong><em>\u0177=\u03b2\u2080+\u03b2\u2081x</em></strong><br>Here \u03b2\u2080 is called the intercept where the line intercepts the y-axis, \u03b2\u2081 is the coefficient or weight of the data points and it is also the slope of the line.<br>Both \u03b2\u2080 and \u03b2\u2081are the weights that are updated in order to get the best fit\u00a0line.</p>\n<p>For Multi Linear Regression, the equation is a little different.<br><strong><em>\u0177=\u03b2\u2080+\u03b2\u2081x\u2081+\u03b2\u2082x\u2082+\u2026+\u03b2\u2099x\u2099</em></strong><strong><br></strong>For more than one input features, We use the above equation to represent a straight line. \u03b2\u2080, \u03b2\u2081, \u03b2\u2082 and \u03b2\u2099 are the coefficients or weights and n is number of input features.</p>\n<p>For Simple Linear Regression, the best fit line will be a two-dimensional line plot. But for Multi Linear Regression, the best fit line will be multi dimensional and can be described using a hyperplane.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/416/1*cvOboIRcEQDf2w8vo9L8qg.png\"><figcaption>Simple Linear Regression plot</figcaption></figure><h4><strong>Cost Function</strong></h4>\n<p>The cost function is the average of the errors(predicted-actual values)for n data points occurred during the training period. We have to minimize this cost function by updating the weights to get the best fit line. The equation for Cost function is as\u00a0follows:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/320/0*iBuU1dZChL6RsN6-.png\"></figure><p>This process is done by plotting weights vs the cost functions. By updating the weights, we can plot for different cost functions. This plotting can be done by taking a hypothesis that the intercept= 0. The resultant graph gives us a U shaped curve called the Gradient\u00a0Descent.</p>\n<h4>GRADIENT DESCENT</h4>\n<p>Gradient descent is used as an optimization algorithm to find the weights for the minimal Cost function. This will lead to finding the best fit line for our data points. The point at which the Cost function is minimal is called the Global\u00a0minima.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/699/1*FeWOP7MFolo9PDnvaaXLPg.png\"><figcaption>Gradient Descent for Linear Regression</figcaption></figure><p>The equation used in Gradient Descent is called the convergence algorithm which is give\u00a0below.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/361/1*lyi3WJA2XxP7a5LzDhbqcA.png\"></figure><p>By repeating the above equation, we will reach convergence i.e. Minimal cost function.</p>\n<p>We navigate to the Global minima by applying a derivative of slope with a small learning rate (i.e. alpha) to the previous weights. If the slope is positive, then we get a positive derivative and if the slope is negative, then we get a negative derivative.</p>\n<p>Here, Learning rate determines at which speed we must move towards the global minima. Having a huge value for learning rate will lead to jumping out of global minima, thus does not converge. Also having a very smaller value of learning rate will take forever for the algorithm to reach global minima. Common learning rates are\u200a\u2014\u200a0.01, 0.001,\u00a00.0001.</p>\n<p>Once the gradient descent algorithm converges, It means that we have reached Global minima or the minimal Cost Function. These weights used to reach the global minima will be our weights for the best fit line equation.</p>\n<p>The cost function used in Linear regression does not create Local minima. Therefore we can worry about that when we go through Neural network where we learn different types of optimizers to solve this\u00a0problem.</p>\n<h4>R\u00b2 and ADJUSTED\u00a0R\u00b2</h4>\n<p>R\u00b2 and Adjusted R\u00b2 are called the coefficient of determination and it tells us the strength of linear relationship that our model can explain.<br>R squared can be defined as how well a model is fit using Linear Regression. The formula for R squared is given\u00a0below.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/404/1*f4AUmkE5Wx112olQULYgBA.png\"></figure><p>Here, SS(Regression) is the sum of squares of residuals or errors, SS(Total) is the total sum of squares i.e. sum of distance between the observed data and its mean. SST tells us how the observed data is dispersed around the\u00a0mean.</p>\n<p>If the R\u00b2 is a bigger number then our model has fitted the data points properly and vice versa. <br>The problem with R squared occurs when we deal with Multi Linear Regression. Adding features to our dataset will increase the value of R\u00b2 even though the features have no correlation with the output variable.</p>\n<p>In order to prevent this overfitting, We use Adjusted R\u00b2 which generalizes the value of R\u00b2 to the optimal value. The formula for Adjusted R\u00b2 is given\u00a0below.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/494/1*z33eWfw-6pu-tBp8ienweg.png\"></figure><p>Here N is the total number of samples or data points and p is the total number of features or independent variables.</p>\n<p>As the number of irrelevant features keeps increasing, the values of Adjusted R\u00b2 keeps decreasing. For relevant features, the R\u00b2 value in the numerator will be increased tremendously, thus impacting the Adjusted R\u00b2 value\u00a0also.</p>\n<h3>End Notes</h3>\n<p>We had a brief into about Machine Learning. We also have covered most of the topics related to Linear Regression. If you are interested to learn the math regarding Gradient descent, then you can refer this blog\u200a\u2014\u200a<a href=\"https://www.analyticsvidhya.com/blog/2021/04/gradient-descent-in-linear-regression/\">https://www.analyticsvidhya.com/blog/2021/04/gradient-descent-in-linear-regression/</a></p>\n<p>Please feel free to connect with me on <a href=\"https://www.linkedin.com/in/vinoth24/\">LinkedIn </a>and share your valuable inputs. Kindly have a look at my <a href=\"https://kasi-vinoth-s-my-data-science-portfolio.webflow.io/\">Portfolio</a>.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=f19b798d90e1\" width=\"1\" height=\"1\" alt=\"\">\n","enclosure":{},"categories":["linear-regression","r-squared","machine-learning","gradient-descent","data-science"]},{"title":"Deployment of your model on Heroku web using Streamlit library","pubDate":"2021-12-03 09:38:45","link":"https://medium.com/@vino24995/deployment-of-your-model-on-heroku-web-using-streamlit-library-e76f9c73ed86?source=rss-1afae9e18583------2","guid":"https://medium.com/p/e76f9c73ed86","author":"Kasi Vinoth S","thumbnail":"https://cdn-images-1.medium.com/max/738/1*SS8OwXX4e614S2fIr1jeAg.png","description":"\n<p>In this article, I am going to walk you through the process of deploying your model onto the <strong>Heroku Web </strong>using <strong>Streamlit</strong> library. To get started, Lets talk about the dataset and the model that we are using in this\u00a0article.</p>\n<p>Our problem statement is to predict whether a company is getting bankrupted or not getting bankrupted. Our sample dataset looks like the\u00a0below.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/738/1*SS8OwXX4e614S2fIr1jeAg.png\"></figure><h3>Exploratory Data\u00a0Analysis</h3>\n<p>The dataset we are going to work with is very simple. It has 250 rows with seven columns(6 features and 1 target). Each feature has 3 discrete values 0, 0.5 and 1 meaning low, medium and high respectively. By EDA process, We understand that the dataset is very clean with no feature engineering required.</p>\n<h3>MODEL BUILDING</h3>\n<p>We have split the data in 3 ways- Train set, Validation set and Test set. We used Validation set to avoid any data leakage to the Test data during model training.</p>\n<p>We have used Neural networks to design our model for better predictions. The hyperparameters were optimized and chosen carefully using KerasTuner to avoid overfitting. The finalized model was showing 99.18% training accuracy and 98.66% testing accuracy with 1 misclassification. The model we built was very satisfactory.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/328/1*Z7Kll1ZJMwG5soYgOz_Law.png\"><figcaption>Confusion matrix and Test\u00a0Accuracy</figcaption></figure><h3>MODEL DEPLOYMENT</h3>\n<p>I think now you must have gotten a hang of the data and model, lets proceed with our primary topic- <strong>Model Deployment.</strong></p>\n<p>Things you will get familiar with after this\u00a0article.</p>\n<ol>\n<li>Using Streamlit to develop and run your app on local\u00a0machine.</li>\n<li>Creating a Heroku account and deploying your app on the\u00a0web.</li>\n</ol>\n<h3>Using Streamlit:</h3>\n<p>Streamlit is an open-source app framework for Data science enthusiasts to create beautiful apps with minimal usage of time. We are choosing Streamlit over Flask because of the fact that<em> no HTML knowledge</em> is required for using Streamlit. Having known the importance of Streamlit, lets get on with our\u00a0code.</p>\n<p>Keras models are pickle-able, But I still recommend using model.save() for saving model to disk and avoiding complications. The trained model is saved and <em>loaded using </em><em>from keras.models import load_model library</em>.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/403/1*1Oz_3Nuxi3tQcyQwF7Uv6Q.png\"></figure><h4>Building our\u00a0App</h4>\n<p>At first, we are going to take inputs for each of our features using st.number_input widget. This method can be used to take only discrete numerical inputs(using parameters) for avoiding\u00a0errors.</p>\n<p>Here st.sidebar is used to pin the input elements to the left, thus allowing users to focus on the content and also to keep it organized.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/872/1*6_1B4Y3YcowKHMK8q2KkTQ.png\"></figure><p>After the input is given, we are going to predict the results using our loaded model. For this process, we are going to use a widget st.button which will activate the <em>predict_bankruptcy</em> function(look through the code)when clicked.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/991/1*aNi0CLLtGMvDOsSCEMxEFg.png\"></figure><p>Now the <em>predict_bankruptcy </em>function returns the output to the results and it is displayed using st.success widget which can display our success message to the\u00a0user.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/326/1*2cpkPQj7-hTd2Wzyf-bgTw.png\"></figure><p>Thus we have successfully explored few Streamlit widgets and methods to predict a model. This will create a basic app but there are lots of methods and parameters to play with to make your app look beautiful. You can understand about a lot of other features of Streamlit through my code in github. I will add my github link at the end of this article for reference.</p>\n<p>If you\u2019re using Jupyter notebook, you will have to save your file as\u00a0.py first. Then you can run your app on your local machine, the process is very simple. You can open your <strong>anaconda command prompt</strong> and type the following.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/285/1*9R_YT8Jw6dvBHFroBuDs7Q.png\"><figcaption>app.py is your streamlit file\u00a0name</figcaption></figure><p>Now your app should run in your default browser or you can copy the URL and paste in your browser to run the app. Ta-da! You have now made a basic Streamlit app for your\u00a0model.</p>\n<h3>Deployment on Heroku\u00a0platform</h3>\n<p>While practicing Data Science, a lot of students get confused when it comes to deploying their model on the web. Don\u2019t worry, I am going try to make this process easy for you. Heroku platform is one of the simpler ways to deploy your model on the\u00a0web.</p>\n<h4>What is\u00a0Heroku?</h4>\n<p>Heroku is a service platform that will enable you to build, run, and operate applications on cloud for\u00a0free.</p>\n<p>Creating an account is the first step in this process. After creating your account, you can got to <strong><em>New \u2192 Create new\u00a0app</em></strong>.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*kslOvhrPjS3IoC4o01ZYGw.png\"></figure><p>Now you have to mention a <em>valid name</em> for your app and choose a host region to deploy from(its either US or Europe), then click on <strong><em>Create\u00a0app</em></strong>.</p>\n<p>Next step is to navigate to the<strong><em> Deploy tab</em></strong> and connect your Github account with\u00a0Heroku.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*poogjO8gQKZqPVdasUXu9g.png\"></figure><p>Your codes are going to get updated to build your app through your <strong>Github repository.</strong></p>\n<p>So lets discuss <em>the prerequisites for your Github repository</em>:</p>\n<ul>\n<li>You must create a <strong><em>new Repository</em></strong>.</li>\n<li>Your <strong><em>Streamlit app file</em></strong> must be added to this repository.</li>\n<li>Your saved\u00a0<strong><em>.h5 trained model file</em></strong> should be\u00a0added.</li>\n<li>\n<strong><em>requirement.txt file</em></strong> must be added. (type pip freeze &gt; requirements.txton your working environment in anaconda prompt to get requirements.txt file).</li>\n<li>\n<strong><em>Procfile</em></strong>\u200a\u2014\u200aa necessary file to run commands by your app in Heroku platform should be added. The format for the procfile is given\u00a0below.</li>\n</ul>\n<pre>web: sh setup.sh &amp;&amp; stream lit run &lt;app file name&gt;</pre>\n<ul><li>\n<strong><em>setup.sh</em></strong>\u200a\u2014\u200aThis file defines the shell environment variables necessary for your code to run in your app. The format for <em>setup.sh file</em> is given\u00a0below.</li></ul>\n<pre>mkdir -p ~/.streamlit/ <br>echo \"\\<br>[server]\\n\\<br>port = $PORT\\n\\<br>enableCORS = false\\n\\<br>headless = true\\n\\<br>\\n\\<br>\" &gt; ~/.streamlit/config.toml</pre>\n<ul><li>In case of any additional files imported in your app code(eg. images, datasets etc.) you must add the source file to your repository.</li></ul>\n<p>Do not worry if you didn\u2019t understand <em>Procfile </em>and <em>setup.sh</em> files, you just need to follow the format to make it\u00a0work.</p>\n<p>I hope all the prerequisites are met, and we can move back to the Heroku platform where we\u00a0left.</p>\n<p>Now you can <strong><em>connect </em></strong>your Github repository to your Heroku account. Next, you should navigate below to the <em>Manual deploy</em> option and choose <em>main</em> branch and click <strong><em>Deploy\u00a0branch</em></strong>.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*XfIFamkBfHKuxCm3QvXLNg.png\"></figure><p>Now you can wait while your app is getting loaded into the Heroku platform.</p>\n<p>Once its done, you will receive a message that <strong>Your app was successfully deployed. </strong>You can click <strong>View</strong> to open your app.<strong> </strong>Ta-da!<strong> </strong><br>You can look up my app on Bankruptcy Prevention at <a href=\"https://bankruptcy-prevention.herokuapp.com/\">https://bankruptcy-prevention.herokuapp.com/</a>.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*vKCH67EjbQ041n0QI5d1jQ.png\"><figcaption>A sample prediction from our successfully deployed\u00a0app</figcaption></figure><blockquote>Note: Once your model is loaded into Heroku platform, there may be some problem caused because of exceeding slug size. So I am going to let you know some tricks to reduce the slug\u00a0size.</blockquote>\n<blockquote>- Try to remove any unwanted files present in your github repository.</blockquote>\n<blockquote>- Try to reduce the versions of packages you have mentioned in your requirements.txt file.</blockquote>\n<blockquote>- Since tensorflow takes lot of memory to get installed in your app, you can use tensorflow-cpu==2.5.0instead of tensorflow==2.7.0to reduce the memory size being\u00a0wasted.</blockquote>\n<p>Link to my github repository(including dataset and all necessary files)\u200a\u2014\u200a<a href=\"https://github.com/Vinoth-24/Bankruptcy-Prevention\"><em>https://github.com/Vinoth-24/Bankruptcy-Prevention</em></a><em>.</em></p>\n<h3>Conclusion</h3>\n<p>From this article, we have learnt how to deploy a working model in local machine as well as Heroku web platform using Streamlit library. I have also discussed about troubleshooting issues related to deployment on Heroku platform.</p>\n<p>In the future, I will work on honing my skills to deliver simple and precise knowledge to the Data Science community. I will unravel some essential Data Science concepts which may look complicated(not really) in my upcoming articles.</p>\n<p>This article is focused to help beginners for the deployment of their Machine learning and Deep learning\u00a0models.</p>\n<p>Any suggestions and critics are warmly welcomed. Thank you for staying till the\u00a0end.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=e76f9c73ed86\" width=\"1\" height=\"1\" alt=\"\">\n","content":"\n<p>In this article, I am going to walk you through the process of deploying your model onto the <strong>Heroku Web </strong>using <strong>Streamlit</strong> library. To get started, Lets talk about the dataset and the model that we are using in this\u00a0article.</p>\n<p>Our problem statement is to predict whether a company is getting bankrupted or not getting bankrupted. Our sample dataset looks like the\u00a0below.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/738/1*SS8OwXX4e614S2fIr1jeAg.png\"></figure><h3>Exploratory Data\u00a0Analysis</h3>\n<p>The dataset we are going to work with is very simple. It has 250 rows with seven columns(6 features and 1 target). Each feature has 3 discrete values 0, 0.5 and 1 meaning low, medium and high respectively. By EDA process, We understand that the dataset is very clean with no feature engineering required.</p>\n<h3>MODEL BUILDING</h3>\n<p>We have split the data in 3 ways- Train set, Validation set and Test set. We used Validation set to avoid any data leakage to the Test data during model training.</p>\n<p>We have used Neural networks to design our model for better predictions. The hyperparameters were optimized and chosen carefully using KerasTuner to avoid overfitting. The finalized model was showing 99.18% training accuracy and 98.66% testing accuracy with 1 misclassification. The model we built was very satisfactory.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/328/1*Z7Kll1ZJMwG5soYgOz_Law.png\"><figcaption>Confusion matrix and Test\u00a0Accuracy</figcaption></figure><h3>MODEL DEPLOYMENT</h3>\n<p>I think now you must have gotten a hang of the data and model, lets proceed with our primary topic- <strong>Model Deployment.</strong></p>\n<p>Things you will get familiar with after this\u00a0article.</p>\n<ol>\n<li>Using Streamlit to develop and run your app on local\u00a0machine.</li>\n<li>Creating a Heroku account and deploying your app on the\u00a0web.</li>\n</ol>\n<h3>Using Streamlit:</h3>\n<p>Streamlit is an open-source app framework for Data science enthusiasts to create beautiful apps with minimal usage of time. We are choosing Streamlit over Flask because of the fact that<em> no HTML knowledge</em> is required for using Streamlit. Having known the importance of Streamlit, lets get on with our\u00a0code.</p>\n<p>Keras models are pickle-able, But I still recommend using model.save() for saving model to disk and avoiding complications. The trained model is saved and <em>loaded using </em><em>from keras.models import load_model library</em>.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/403/1*1Oz_3Nuxi3tQcyQwF7Uv6Q.png\"></figure><h4>Building our\u00a0App</h4>\n<p>At first, we are going to take inputs for each of our features using st.number_input widget. This method can be used to take only discrete numerical inputs(using parameters) for avoiding\u00a0errors.</p>\n<p>Here st.sidebar is used to pin the input elements to the left, thus allowing users to focus on the content and also to keep it organized.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/872/1*6_1B4Y3YcowKHMK8q2KkTQ.png\"></figure><p>After the input is given, we are going to predict the results using our loaded model. For this process, we are going to use a widget st.button which will activate the <em>predict_bankruptcy</em> function(look through the code)when clicked.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/991/1*aNi0CLLtGMvDOsSCEMxEFg.png\"></figure><p>Now the <em>predict_bankruptcy </em>function returns the output to the results and it is displayed using st.success widget which can display our success message to the\u00a0user.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/326/1*2cpkPQj7-hTd2Wzyf-bgTw.png\"></figure><p>Thus we have successfully explored few Streamlit widgets and methods to predict a model. This will create a basic app but there are lots of methods and parameters to play with to make your app look beautiful. You can understand about a lot of other features of Streamlit through my code in github. I will add my github link at the end of this article for reference.</p>\n<p>If you\u2019re using Jupyter notebook, you will have to save your file as\u00a0.py first. Then you can run your app on your local machine, the process is very simple. You can open your <strong>anaconda command prompt</strong> and type the following.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/285/1*9R_YT8Jw6dvBHFroBuDs7Q.png\"><figcaption>app.py is your streamlit file\u00a0name</figcaption></figure><p>Now your app should run in your default browser or you can copy the URL and paste in your browser to run the app. Ta-da! You have now made a basic Streamlit app for your\u00a0model.</p>\n<h3>Deployment on Heroku\u00a0platform</h3>\n<p>While practicing Data Science, a lot of students get confused when it comes to deploying their model on the web. Don\u2019t worry, I am going try to make this process easy for you. Heroku platform is one of the simpler ways to deploy your model on the\u00a0web.</p>\n<h4>What is\u00a0Heroku?</h4>\n<p>Heroku is a service platform that will enable you to build, run, and operate applications on cloud for\u00a0free.</p>\n<p>Creating an account is the first step in this process. After creating your account, you can got to <strong><em>New \u2192 Create new\u00a0app</em></strong>.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*kslOvhrPjS3IoC4o01ZYGw.png\"></figure><p>Now you have to mention a <em>valid name</em> for your app and choose a host region to deploy from(its either US or Europe), then click on <strong><em>Create\u00a0app</em></strong>.</p>\n<p>Next step is to navigate to the<strong><em> Deploy tab</em></strong> and connect your Github account with\u00a0Heroku.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*poogjO8gQKZqPVdasUXu9g.png\"></figure><p>Your codes are going to get updated to build your app through your <strong>Github repository.</strong></p>\n<p>So lets discuss <em>the prerequisites for your Github repository</em>:</p>\n<ul>\n<li>You must create a <strong><em>new Repository</em></strong>.</li>\n<li>Your <strong><em>Streamlit app file</em></strong> must be added to this repository.</li>\n<li>Your saved\u00a0<strong><em>.h5 trained model file</em></strong> should be\u00a0added.</li>\n<li>\n<strong><em>requirement.txt file</em></strong> must be added. (type pip freeze &gt; requirements.txton your working environment in anaconda prompt to get requirements.txt file).</li>\n<li>\n<strong><em>Procfile</em></strong>\u200a\u2014\u200aa necessary file to run commands by your app in Heroku platform should be added. The format for the procfile is given\u00a0below.</li>\n</ul>\n<pre>web: sh setup.sh &amp;&amp; stream lit run &lt;app file name&gt;</pre>\n<ul><li>\n<strong><em>setup.sh</em></strong>\u200a\u2014\u200aThis file defines the shell environment variables necessary for your code to run in your app. The format for <em>setup.sh file</em> is given\u00a0below.</li></ul>\n<pre>mkdir -p ~/.streamlit/ <br>echo \"\\<br>[server]\\n\\<br>port = $PORT\\n\\<br>enableCORS = false\\n\\<br>headless = true\\n\\<br>\\n\\<br>\" &gt; ~/.streamlit/config.toml</pre>\n<ul><li>In case of any additional files imported in your app code(eg. images, datasets etc.) you must add the source file to your repository.</li></ul>\n<p>Do not worry if you didn\u2019t understand <em>Procfile </em>and <em>setup.sh</em> files, you just need to follow the format to make it\u00a0work.</p>\n<p>I hope all the prerequisites are met, and we can move back to the Heroku platform where we\u00a0left.</p>\n<p>Now you can <strong><em>connect </em></strong>your Github repository to your Heroku account. Next, you should navigate below to the <em>Manual deploy</em> option and choose <em>main</em> branch and click <strong><em>Deploy\u00a0branch</em></strong>.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*XfIFamkBfHKuxCm3QvXLNg.png\"></figure><p>Now you can wait while your app is getting loaded into the Heroku platform.</p>\n<p>Once its done, you will receive a message that <strong>Your app was successfully deployed. </strong>You can click <strong>View</strong> to open your app.<strong> </strong>Ta-da!<strong> </strong><br>You can look up my app on Bankruptcy Prevention at <a href=\"https://bankruptcy-prevention.herokuapp.com/\">https://bankruptcy-prevention.herokuapp.com/</a>.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*vKCH67EjbQ041n0QI5d1jQ.png\"><figcaption>A sample prediction from our successfully deployed\u00a0app</figcaption></figure><blockquote>Note: Once your model is loaded into Heroku platform, there may be some problem caused because of exceeding slug size. So I am going to let you know some tricks to reduce the slug\u00a0size.</blockquote>\n<blockquote>- Try to remove any unwanted files present in your github repository.</blockquote>\n<blockquote>- Try to reduce the versions of packages you have mentioned in your requirements.txt file.</blockquote>\n<blockquote>- Since tensorflow takes lot of memory to get installed in your app, you can use tensorflow-cpu==2.5.0instead of tensorflow==2.7.0to reduce the memory size being\u00a0wasted.</blockquote>\n<p>Link to my github repository(including dataset and all necessary files)\u200a\u2014\u200a<a href=\"https://github.com/Vinoth-24/Bankruptcy-Prevention\"><em>https://github.com/Vinoth-24/Bankruptcy-Prevention</em></a><em>.</em></p>\n<h3>Conclusion</h3>\n<p>From this article, we have learnt how to deploy a working model in local machine as well as Heroku web platform using Streamlit library. I have also discussed about troubleshooting issues related to deployment on Heroku platform.</p>\n<p>In the future, I will work on honing my skills to deliver simple and precise knowledge to the Data Science community. I will unravel some essential Data Science concepts which may look complicated(not really) in my upcoming articles.</p>\n<p>This article is focused to help beginners for the deployment of their Machine learning and Deep learning\u00a0models.</p>\n<p>Any suggestions and critics are warmly welcomed. Thank you for staying till the\u00a0end.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=e76f9c73ed86\" width=\"1\" height=\"1\" alt=\"\">\n","enclosure":{},"categories":["deep-learning","heroku","streamlit","beginners-guide","machine-learning"]}]}